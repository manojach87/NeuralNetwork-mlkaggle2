{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Network_Model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manojach87/mlkaggle2/blob/master/Neural_Network_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "XMUHOs5vG7Tx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "global pd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf    \n",
        "from pandas import DataFrame  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cv26WvGVHF_5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U01SqgfRHIIx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, LeakyReLU\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dy5JsnC3HKTB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "now = datetime.now()\n",
        "global epochs\n",
        "trainings=5000\n",
        "checkpoint_interval=1\n",
        "epochs = 1\n",
        "tf.set_random_seed(0)\n",
        "model_filepath='./model.save'\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WxOcF3ZAHOqJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('./train_Y.zip', 'r')\n",
        "zip_ref.extractall('./')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OnYVId10IyfH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = pd.read_csv(\"./train_X.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sna-wKSOI8A3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y = pd.read_csv(\"./train_Y.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MJAy3T7II-vg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred = pd.read_csv('./test_X.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RgwxG7xEJCx7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X.set_index(\"idx\", inplace=True)\n",
        "Y.set_index('idx', inplace=True)\n",
        "pred.set_index('idx', inplace=True)\n",
        "\n",
        "# Normalize Data\n",
        "Xnames = X.columns\n",
        "prednames = pred.columns\n",
        "X = tf.keras.utils.normalize(X.values)\n",
        "pred = tf.keras.utils.normalize(pred.values)\n",
        "Y=Y.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tImQVi9KJITw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XAN2dpbtJKih",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#KNN can't read panda df's so need to convert all df's \n",
        "#to values only by removing headers\n",
        "\n",
        "\n",
        "y_trainV = y_train\n",
        "y_testV = y_test\n",
        "X_testV = X_test\n",
        "X_trainV = X_train\n",
        "predV = pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "07GDdFixJMwh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y_train_1h = y_trainV\n",
        "Y_test_1h = y_testV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NefTWSZIJPri",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def buildNN():\n",
        "    global model\n",
        "    model = Sequential()\n",
        "    model.add(Dense (108, input_dim = 54, activation = 'relu'))\n",
        "    model.add(Dense (500, activation = 'relu'))\n",
        "    model.add(Dense (500, activation = 'relu'))\n",
        "    model.add(Dense (500, activation = 'relu'))\n",
        "    #model.add(Dense (72, activation = 'relu'))\n",
        "    #model.add(Dense (64, activation = 'relu'))\n",
        "    #model.add(Dense (48, activation = 'relu'))\n",
        "    #model.add(Dense (32, activation = 'relu'))\n",
        "    #model.add(Dense (16, activation = 'relu'))\n",
        "    model.add(Dense (8,   activation = 'softmax'))\n",
        "    #model.compile(loss = tf.losses.softmax_cross_entropy,\n",
        "    #              optimizer = 'adam',\n",
        "    #              metrics = ['accuracy']\n",
        "    #              #,steps_per_epoch=1\n",
        "    #              )\n",
        "    model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              #loss='poisson',\n",
        "              #loss='kullback_leibler_divergence',\n",
        "              #loss='cosine_proximity',\n",
        "              #loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AgidQ4Usd3SG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nZKXHfMLJSs2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def fitModel(epochs):\n",
        "    model.fit(X_trainV, Y_train_1h, epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cgJI9MauJVDi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluateModel():\n",
        "    global Y_pred\n",
        "    global score\n",
        "    print(model.evaluate(X_testV, Y_test_1h)) \n",
        "    Y_pred = model.predict(pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gc1N4th-JW8q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def writeResults():\n",
        "    global df\n",
        "    df = DataFrame({'t1': np.argmax(Y_pred, axis=1)})\n",
        "    df.index = np.arange(1, len(Y_pred) + 1)\n",
        "    df.to_csv(str(epochs) + 'Epochs_' + now.strftime('%b%w_%H,%M') + '.csv', index_label='idx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HV9AAm6uJY7q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "buildNN()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-hLsX11Le9P6",
        "colab_type": "code",
        "outputId": "d235ff78-c9c0-429b-d13b-5df0e336e6e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "model=tf.keras.models.load_model(model_filepath)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8MPtVedWJbQz",
        "colab_type": "code",
        "outputId": "a0b3e7e2-4561-482c-d4bf-2d5ec615e698",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1703
        }
      },
      "cell_type": "code",
      "source": [
        "#model.fit(X_trainV, Y_train_1h, epochs=epochs, callbacks=[cp_callback])\n",
        "for i in range(trainings):\n",
        "  print(\"Training \"+str(i+1)+\"/\"+str(trainings))\n",
        "  model.fit(X_trainV, Y_train_1h, epochs=epochs)\n",
        "  if(i%checkpoint_interval==checkpoint_interval-1):\n",
        "    tf.keras.models.save_model(model,model_filepath)\n",
        "    print(\"Model from training \"+str(i+1)+\" saved!\" )\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training 1/5000\n",
            "261455/261455 [==============================] - 110s 420us/sample - loss: 0.3968 - acc: 0.8298\n",
            "Model from training 1 saved!\n",
            "Training 2/5000\n",
            "261455/261455 [==============================] - 107s 408us/sample - loss: 0.3568 - acc: 0.8467\n",
            "Model from training 2 saved!\n",
            "Training 3/5000\n",
            "261455/261455 [==============================] - 113s 431us/sample - loss: 0.3402 - acc: 0.8541\n",
            "Model from training 3 saved!\n",
            "Training 4/5000\n",
            "261455/261455 [==============================] - 109s 418us/sample - loss: 0.3280 - acc: 0.8601\n",
            "Model from training 4 saved!\n",
            "Training 5/5000\n",
            "261455/261455 [==============================] - 102s 391us/sample - loss: 0.3160 - acc: 0.8650\n",
            "Model from training 5 saved!\n",
            "Training 6/5000\n",
            "261455/261455 [==============================] - 102s 390us/sample - loss: 0.3075 - acc: 0.8696\n",
            "Model from training 6 saved!\n",
            "Training 7/5000\n",
            "261455/261455 [==============================] - 102s 389us/sample - loss: 0.2957 - acc: 0.8746\n",
            "Model from training 7 saved!\n",
            "Training 8/5000\n",
            "261455/261455 [==============================] - 97s 371us/sample - loss: 0.2886 - acc: 0.8780\n",
            "Model from training 8 saved!\n",
            "Training 9/5000\n",
            "261455/261455 [==============================] - 98s 376us/sample - loss: 0.2797 - acc: 0.8816\n",
            "Model from training 9 saved!\n",
            "Training 10/5000\n",
            "261455/261455 [==============================] - 97s 371us/sample - loss: 0.2738 - acc: 0.8849\n",
            "Model from training 10 saved!\n",
            "Training 11/5000\n",
            "261455/261455 [==============================] - 95s 364us/sample - loss: 0.2675 - acc: 0.8877\n",
            "Model from training 11 saved!\n",
            "Training 12/5000\n",
            "261455/261455 [==============================] - 100s 382us/sample - loss: 0.2615 - acc: 0.8905\n",
            "Model from training 12 saved!\n",
            "Training 13/5000\n",
            "261455/261455 [==============================] - 100s 382us/sample - loss: 0.2565 - acc: 0.8925\n",
            "Model from training 13 saved!\n",
            "Training 14/5000\n",
            "261455/261455 [==============================] - 98s 374us/sample - loss: 0.2503 - acc: 0.8950\n",
            "Model from training 14 saved!\n",
            "Training 15/5000\n",
            "261455/261455 [==============================] - 98s 376us/sample - loss: 0.2461 - acc: 0.8978\n",
            "Model from training 15 saved!\n",
            "Training 16/5000\n",
            "261455/261455 [==============================] - 102s 392us/sample - loss: 0.2411 - acc: 0.9000\n",
            "Model from training 16 saved!\n",
            "Training 17/5000\n",
            "261455/261455 [==============================] - 100s 384us/sample - loss: 0.2376 - acc: 0.9016\n",
            "Model from training 17 saved!\n",
            "Training 18/5000\n",
            "261455/261455 [==============================] - 100s 381us/sample - loss: 0.2347 - acc: 0.9029\n",
            "Model from training 18 saved!\n",
            "Training 19/5000\n",
            "261455/261455 [==============================] - 103s 392us/sample - loss: 0.2302 - acc: 0.9045\n",
            "Model from training 19 saved!\n",
            "Training 20/5000\n",
            "261455/261455 [==============================] - 103s 395us/sample - loss: 0.2270 - acc: 0.9059\n",
            "Model from training 20 saved!\n",
            "Training 21/5000\n",
            "261455/261455 [==============================] - 98s 375us/sample - loss: 0.2245 - acc: 0.9068\n",
            "Model from training 21 saved!\n",
            "Training 22/5000\n",
            "261455/261455 [==============================] - 101s 388us/sample - loss: 0.2203 - acc: 0.9091\n",
            "Model from training 22 saved!\n",
            "Training 23/5000\n",
            "261455/261455 [==============================] - 102s 389us/sample - loss: 0.2176 - acc: 0.9105\n",
            "Model from training 23 saved!\n",
            "Training 24/5000\n",
            "261455/261455 [==============================] - 98s 375us/sample - loss: 0.2131 - acc: 0.9125\n",
            "Model from training 24 saved!\n",
            "Training 25/5000\n",
            "261455/261455 [==============================] - 98s 375us/sample - loss: 0.2109 - acc: 0.9132\n",
            "Model from training 25 saved!\n",
            "Training 26/5000\n",
            "261455/261455 [==============================] - 98s 374us/sample - loss: 0.2084 - acc: 0.9148\n",
            "Model from training 26 saved!\n",
            "Training 27/5000\n",
            "261455/261455 [==============================] - 97s 369us/sample - loss: 0.2065 - acc: 0.9153\n",
            "Model from training 27 saved!\n",
            "Training 28/5000\n",
            "261455/261455 [==============================] - 97s 371us/sample - loss: 0.2052 - acc: 0.9162\n",
            "Model from training 28 saved!\n",
            "Training 29/5000\n",
            "261455/261455 [==============================] - 97s 373us/sample - loss: 0.2015 - acc: 0.9177\n",
            "Model from training 29 saved!\n",
            "Training 30/5000\n",
            "261455/261455 [==============================] - 96s 369us/sample - loss: 0.2006 - acc: 0.9184\n",
            "Model from training 30 saved!\n",
            "Training 31/5000\n",
            "261455/261455 [==============================] - 98s 373us/sample - loss: 0.1979 - acc: 0.9193\n",
            "Model from training 31 saved!\n",
            "Training 32/5000\n",
            "261455/261455 [==============================] - 98s 374us/sample - loss: 0.1956 - acc: 0.9206\n",
            "Model from training 32 saved!\n",
            "Training 33/5000\n",
            "135616/261455 [==============>...............] - ETA: 46s - loss: 0.1912 - acc: 0.9218Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8DsBjQSOJfcj",
        "colab_type": "code",
        "outputId": "8236be0a-e10d-47b3-b4e4-cf4b0e8c6e92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "evaluateModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65364/65364 [==============================] - 2s 38us/sample - loss: 0.2783 - acc: 0.8887\n",
            "[0.27832730027009933, 0.8887461]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TlHGWfyeJpSY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "writeResults()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Ng6yWZhJwon",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def buildNN():\n",
        "    global model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(53, activation='relu', input_dim = 53))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(500, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(500, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(8, activation='softmax'))\n",
        "    model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gvtmcDVbK0Gq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}